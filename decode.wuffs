pub struct decoder?(
	window_size base.u64,
)

pub status "?not a frame"
pub status "?frame reserved bit was set"
pub status "?reserved block type found"
pub status "?block size is larger than 128KiB"
pub status "?block size is larger than window size"

pub status "?TODO"

pub func decoder.decode?(dst base.io_writer, src base.io_reader) {
	var z base.status
	while args.src.available() > 0 {
		z =? this.decode_frame?(dst:args.dst, src:args.src)
		if z.is_suspension() {
			yield z
		}
		if z.is_error() {
			return z
		}
	}
}

pri func decoder.decode_frame?(dst base.io_writer, src base.io_reader) {
	var magic base.u32
	var frame_size base.u32
	var frame_header base.u8
	var fcs_flag base.u8[..0x3]
	var fcs_field_size base.u8
	var single_segment base.bool
	var frame_cont_size base.u64
	var hashing base.bool
	var dict_id_flag base.u8
	var block_header base.u32[..0xFFFFFF]
	var is_last_block base.bool
	var z base.status
	var sum base.u32

	magic = args.src.read_u32le?()
	if (magic >= frame_magic_skip_first) and (magic <= frame_magic_skip_last) {
		frame_size = args.src.read_u32le?()
		args.src.skip?(n:frame_size)
		return ok
	}
	if magic != frame_magic_number {
		return "?not a frame"
	}

	frame_header = args.src.read_u8?()

	fcs_flag = frame_header >> 6
	fcs_field_size = fcs_field_sizes[fcs_flag]

	single_segment = ((frame_header >> 5) & 1) == 1
	if (fcs_flag == 0) and single_segment {
		fcs_field_size = 1
	}

	if fcs_field_size == 1 {
		frame_cont_size = args.src.read_u8_as_u64?()
	} else if fcs_field_size == 2 {
		frame_cont_size = args.src.read_u16le_as_u64?()
		frame_cont_size += 256
	} else if fcs_field_size == 4 {
		frame_cont_size = args.src.read_u32le_as_u64?()
	} else if fcs_field_size == 8 {
		frame_cont_size = args.src.read_u64le?()
	} else {
		return "?TODO" // prove this can't happen?
	}

	this.window_size = min_window_size
	if not single_segment {
		return "?TODO"
	} else {
		this.window_size = frame_cont_size
	}

	if ((frame_header >> 3) & 1) == 1 {
		return "?frame reserved bit was set"
	}

	hashing = ((frame_header >> 2) & 1) == 1

	dict_id_flag = frame_header & 3
	if dict_id_flag > 0 {
		return "?TODO" // read and use dictionary ID
	}

	while true {
		block_header = args.src.read_u24le_as_u32?()

		is_last_block = (block_header & 1) == 1
		z =? this.decode_block?(dst:args.dst, src:args.src, header:block_header)
		if z.is_suspension() {
			yield z
		}
		if z.is_error() {
			return z
		}
		if is_last_block {
			break
		}
	}
	if hashing {
		sum = args.src.read_u32le?()
		// TODO: check the hash
	}
}

pri func decoder.decode_block?(dst base.io_writer, src base.io_reader, header base.u32[..0xFFFFFF]) {
	var block_size base.u32
	var block_type base.u8
	var b base.u8
	var i base.u32

	block_size = args.header >> 3
	if block_size > max_block_size {
		return "?block size is larger than 128KiB"
	}
	if (block_size as base.u64) > this.window_size {
		return "?block size is larger than window size"
	}
	block_type = ((args.header >> 1) & 3) as base.u8

	if block_type == block_type_raw {
		args.dst.copy_n_from_reader!(n:block_size, r:args.src)
	} else if block_type == block_type_rle {
		b = args.src.read_u8?()
		while i < block_size,
			inv block_size <= max_block_size {

			// TODO: hopefully clean up once this issue is
			// fixed: https://github.com/google/wuffs/issues/11
			assert i <= max_block_size via "a <= b: a <= c; c <= b"(c:block_size)
			assert i <= 131072 via "a <= b: a <= c; c == b"(c:max_block_size)

			args.dst.write_u8?(x:b)
			i += 1
		}
	} else if block_type == block_type_compressed {
		return "?TODO"
	} else {
		return "?reserved block type found"
	}
}
